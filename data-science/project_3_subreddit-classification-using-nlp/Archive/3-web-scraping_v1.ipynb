{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!conda install -c conda-forge imbalanced-learn --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,  roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59129, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.read_csv('datasets/combined.csv')\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select X and y columns we need\n",
    "df =  combined[['Subreddit', 'preprocessed_words']]\n",
    "\n",
    "# add label for classification\n",
    "df['is_amd'] = df['Subreddit'].apply(lambda x: 1 if x == \"AMD\" else 0)\n",
    "df = df.drop(columns = 'Subreddit')\n",
    "df = df.rename(columns={'preprocessed_words':'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_amd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>keeps its price from the vram it has a is a ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it s not you just a combo of the game running ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>starfield is cpu heavy which one do you have a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the game is just awfully optimized i just upgr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i tried using fsr but i did nt see any noticib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_amd\n",
       "0  keeps its price from the vram it has a is a ta...       0\n",
       "1  it s not you just a combo of the game running ...       0\n",
       "2  starfield is cpu heavy which one do you have a...       0\n",
       "3  the game is just awfully optimized i just upgr...       0\n",
       "4  i tried using fsr but i did nt see any noticib...       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Stopwords\n",
    "custom_stopwords = [ \"subreddit\", \"reddit\"]  # remove these words as it is not meaningful for our analysis\n",
    "stopwords_list = list(set(stopwords.words('english') + custom_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook on Modelling, I will only be considering the \"text\" column of the scraped dataset, and this has been pre-processed in notebook 2. This ensures that our model can be properly trained on the content of the subreddit posts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline \n",
    "We always begin with creating a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_amd\n",
       "1    0.634545\n",
       "0    0.365455\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model\n",
    "X = df['text']\n",
    "y = df['is_amd']\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Steps I took for this section:\n",
    "1. Train Test Split\n",
    "2. Instantiating Vectorizers and Models\n",
    "3. Creating a User Define Function* with Scikit-learn's Pipeline tool that will help calculate the relevant classification metrics from each model (Metrics include Accuracy, Specificity and F1_Score)\n",
    "4. Evaluate best model\n",
    "5. Tune Hyper-parameters of best model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47303,)\n",
      "(11826,)\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify = y)\n",
    "X_train = X_train.values.astype('U')\n",
    "X_test = X_test.values.astype('U')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words=stopwords_list)\n",
    "cvec.fit(X_train)\n",
    "X_train = cvec.transform(X_train) #transform the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aaa' 'aaaaa' ... 'zx' 'zz' 'zzx']\n",
      "(47303, 32124)\n"
     ]
    }
   ],
   "source": [
    "print(cvec.get_feature_names_out())\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test\n",
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine train and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify = y)\n",
    "X_train = X_train.values.astype('U')\n",
    "X_test = X_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Baseline model, we can see moderate imbalance in our dataset (65%-35%). Hence, we can use the SMOTE technique to correct this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47303,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/current_repodata.json HTTP/1.1\" 304 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['in most cases ai is if else combo i m working with it ai is a magic word for sale'\n 'ha i did the same thing on my asus board i was like how the fuck do you disable this thing lol'\n 'man amd did an amd again and copied nvidia rtx ti shenanigans at least the rxxt is much more obvious choice over the rtx ti gb and obviously gb honestly would pay bucks more for rtx for the raytracing'\n ... 'deleted'\n 'third party sellers on amazon are scalping it for usd and apparently it s still selling at that price'\n 'i m pretty sure you will be disappointed because after today s todd interview i am it s clear as day they wo nt do any real improvements'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\project_3\\3-web-scraping_v1.ipynb Cell 20\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m##Now we can create synthetic data for our training set\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sm \u001b[39m=\u001b[39m SMOTE()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Xsm_train, ysm_train \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mfit_resample(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\imblearn\\base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m check_classification_targets(y)\n\u001b[0;32m    105\u001b[0m arrays_transformer \u001b[39m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m--> 106\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    112\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\imblearn\\base.py:161\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    159\u001b[0m     accept_sparse \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    160\u001b[0m y, binarize_y \u001b[39m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 161\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, reset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse)\n\u001b[0;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['in most cases ai is if else combo i m working with it ai is a magic word for sale'\n 'ha i did the same thing on my asus board i was like how the fuck do you disable this thing lol'\n 'man amd did an amd again and copied nvidia rtx ti shenanigans at least the rxxt is much more obvious choice over the rtx ti gb and obviously gb honestly would pay bucks more for rtx for the raytracing'\n ... 'deleted'\n 'third party sellers on amazon are scalping it for usd and apparently it s still selling at that price'\n 'i m pretty sure you will be disappointed because after today s todd interview i am it s clear as day they wo nt do any real improvements'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "##Now we can create synthetic data for our training set\n",
    "\n",
    "sm = SMOTE()\n",
    "Xsm_train, ysm_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Instantiation of Vectorizers and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be exploring different Classification algorithms and using both Count Vectorizer or Term Frequency-Inverse Document Frequency (TFIDF) transformers:\n",
    "- Count Vectorizer: Takes every word as a token, and uses it as a feature.\n",
    "- TFIFD: accounts for frequency of a word in a given document and the frequency between documents. Word importance increases proportionally to the number of times it appears in a document, but is offset by frequency of word in entire corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Vectorizers\n",
    "vectorizers = {'cvec': CountVectorizer(stop_words=stopwords_list),\n",
    "               'tvec': TfidfVectorizer(stop_words=stopwords_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instiantiate models\n",
    "models = {'nb': MultinomialNB(),\n",
    "          'log_reg': LogisticRegression(max_iter=500, random_state=123),\n",
    "          'rf': RandomForestClassifier(random_state=123),\n",
    "          'knn': KNeighborsClassifier()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. User Define Function - inputs required are vectorizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_results = []\n",
    "\n",
    "def clf_model(vec, mod, cv_num, X_train, y_train, vec_params={},  grid_search=False):   # option to include Grid Search\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "            (vec, vectorizers[vec]),\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    if grid_search:\n",
    "        if mod == 'rf':\n",
    "            rs = RandomizedSearchCV(pipe, param_distributions = {**vec_params}, cv=cv_num, verbose=1, n_jobs=-1) \n",
    "            rs.fit(X_train, y_train)\n",
    "            pipe = rs\n",
    "\n",
    "        else:\n",
    "            gs = GridSearchCV(pipe, param_grid = {**vec_params}, cv=cv_num, verbose=1, n_jobs=-1)\n",
    "            gs.fit(X_train, y_train)\n",
    "            pipe = gs\n",
    "        \n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    tn, fp, fn, tp = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "    acc = (tp + tn)/ (tp+tn+fp+fn)\n",
    "    spec = tn / (tn + fp)\n",
    "    \n",
    "    # Retrieve metrics\n",
    "    results['Model'] = mod\n",
    "    results['Vectorizer'] = vec\n",
    "    results['Train Score'] = pipe.score(X_train, y_train)\n",
    "    results['Test Score'] = pipe.score(X_test, y_test)\n",
    "    results['Accuracy'] = acc\n",
    "    results['Specificity'] = spec\n",
    "    results['f_score'] = f1_score(y_test, preds)\n",
    "    results['ROC_AUC'] = roc_auc_score(y_test, preds)\n",
    "\n",
    "    \n",
    "    \n",
    "    if grid_search:\n",
    "        tuning_results.append(results)\n",
    "        print(f\"--- Best Parameters for {mod},{vec} ---\")\n",
    "        display(pipe.best_params_)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        df_results.append(results)\n",
    "    \n",
    "    print(f\"--- METRICS for {mod},{vec} ---\")\n",
    "    display(results)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for nb,cvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'nb',\n",
       " 'Vectorizer': 'cvec',\n",
       " 'Train Score': 0.7876878844893559,\n",
       " 'Test Score': 0.7323693556570269,\n",
       " 'Accuracy': 0.7323693556570269,\n",
       " 'Specificity': 0.5826006478482184,\n",
       " 'f_score': 0.7951588893922723,\n",
       " 'ROC_AUC': 0.7006153559070516}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for nb,tvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'nb',\n",
       " 'Vectorizer': 'tvec',\n",
       " 'Train Score': 0.7469082299219922,\n",
       " 'Test Score': 0.7006595636732623,\n",
       " 'Accuracy': 0.7006595636732623,\n",
       " 'Specificity': 0.23739009717723275,\n",
       " 'f_score': 0.8039867109634551,\n",
       " 'ROC_AUC': 0.6024370528530087}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "cvec_nb = clf_model('cvec', 'nb', 5)\n",
    "tvec_nb = clf_model('tvec', 'nb', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for log_reg,cvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'log_reg',\n",
       " 'Vectorizer': 'cvec',\n",
       " 'Train Score': 0.8479166226243579,\n",
       " 'Test Score': 0.736935565702689,\n",
       " 'Accuracy': 0.736935565702689,\n",
       " 'Specificity': 0.5367885238315595,\n",
       " 'f_score': 0.8043519275517262,\n",
       " 'ROC_AUC': 0.6945003386748416}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for log_reg,tvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'log_reg',\n",
       " 'Vectorizer': 'tvec',\n",
       " 'Train Score': 0.7980677758281716,\n",
       " 'Test Score': 0.7448841535599526,\n",
       " 'Accuracy': 0.7448841535599526,\n",
       " 'Specificity': 0.501850994909764,\n",
       " 'f_score': 0.814873903172363,\n",
       " 'ROC_AUC': 0.6933562010796155}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "cvec_lr = clf_model('cvec', 'log_reg', 5)\n",
    "tvec_lr = clf_model('tvec', 'log_reg', 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for log_reg,cvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'log_reg',\n",
       " 'Vectorizer': 'cvec',\n",
       " 'Train Score': 0.8479166226243579,\n",
       " 'Test Score': 0.736935565702689,\n",
       " 'Accuracy': 0.736935565702689,\n",
       " 'Specificity': 0.5367885238315595,\n",
       " 'f_score': 0.8043519275517262,\n",
       " 'ROC_AUC': 0.6945003386748416}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for log_reg,tvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'log_reg',\n",
       " 'Vectorizer': 'tvec',\n",
       " 'Train Score': 0.7980677758281716,\n",
       " 'Test Score': 0.7448841535599526,\n",
       " 'Accuracy': 0.7448841535599526,\n",
       " 'Specificity': 0.501850994909764,\n",
       " 'f_score': 0.814873903172363,\n",
       " 'ROC_AUC': 0.6933562010796155}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression using SMOTE data\n",
    "cvec_lr = clf_model('cvec', 'log_reg', 5, Xsm_train, ysm_train)\n",
    "tvec_lr = clf_model('tvec', 'log_reg', 5, Xsm_train, ysm_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tiffa\\AppData\\Local\\Temp\\ipykernel_95988\\699685553.py\", line 2, in <module>\n",
      "    cvec_rf = clf_model('cvec', 'rf', 3) # put 3-fold cross validation for random forest to reduce runtime\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tiffa\\AppData\\Local\\Temp\\ipykernel_95988\\3848433570.py\", line 24, in clf_model\n",
      "    pipe.fit(X_train, y_train)\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    pipeline.\n",
      "        ^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    else:\n",
      "          \n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\joblib\\parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\joblib\\parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n",
      "    return tree\n",
      "        ^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    The class log-probabilities of the input samples. The order of the\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 443, in _fit\n",
      "    return predictions\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\executing\\executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "cvec_rf = clf_model('cvec', 'rf', 3) # put 3-fold cross validation for random forest to reduce runtime\n",
    "tvec_rf = clf_model('tvec', 'rf', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for knn,cvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'knn',\n",
       " 'Vectorizer': 'cvec',\n",
       " 'Train Score': 0.7651945965372176,\n",
       " 'Test Score': 0.6431591408760359,\n",
       " 'Accuracy': 0.6431591408760359,\n",
       " 'Specificity': 0.4449329014345211,\n",
       " 'f_score': 0.7292441935069934,\n",
       " 'ROC_AUC': 0.6011311628707786}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for knn,tvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'knn',\n",
       " 'Vectorizer': 'tvec',\n",
       " 'Train Score': 0.6845020400397438,\n",
       " 'Test Score': 0.6421444275325554,\n",
       " 'Accuracy': 0.6421444275325554,\n",
       " 'Specificity': 0.07681628875520592,\n",
       " 'f_score': 0.7743655363616976,\n",
       " 'ROC_AUC': 0.5222834109021233}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>f_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.787688</td>\n",
       "      <td>0.732369</td>\n",
       "      <td>0.732369</td>\n",
       "      <td>0.582601</td>\n",
       "      <td>0.795159</td>\n",
       "      <td>0.700615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.746908</td>\n",
       "      <td>0.700660</td>\n",
       "      <td>0.700660</td>\n",
       "      <td>0.237390</td>\n",
       "      <td>0.803987</td>\n",
       "      <td>0.602437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.990529</td>\n",
       "      <td>0.728902</td>\n",
       "      <td>0.728902</td>\n",
       "      <td>0.499769</td>\n",
       "      <td>0.801191</td>\n",
       "      <td>0.680321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.990445</td>\n",
       "      <td>0.728057</td>\n",
       "      <td>0.728057</td>\n",
       "      <td>0.442619</td>\n",
       "      <td>0.806382</td>\n",
       "      <td>0.667538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.765195</td>\n",
       "      <td>0.643159</td>\n",
       "      <td>0.643159</td>\n",
       "      <td>0.444933</td>\n",
       "      <td>0.729244</td>\n",
       "      <td>0.601131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>knn</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.684502</td>\n",
       "      <td>0.642144</td>\n",
       "      <td>0.642144</td>\n",
       "      <td>0.076816</td>\n",
       "      <td>0.774366</td>\n",
       "      <td>0.522283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Vectorizer  Train Score  Test Score  Accuracy  Specificity   f_score  \\\n",
       "0    nb       cvec     0.787688    0.732369  0.732369     0.582601  0.795159   \n",
       "1    nb       tvec     0.746908    0.700660  0.700660     0.237390  0.803987   \n",
       "2    rf       cvec     0.990529    0.728902  0.728902     0.499769  0.801191   \n",
       "3    rf       tvec     0.990445    0.728057  0.728057     0.442619  0.806382   \n",
       "4   knn       cvec     0.765195    0.643159  0.643159     0.444933  0.729244   \n",
       "5   knn       tvec     0.684502    0.642144  0.642144     0.076816  0.774366   \n",
       "\n",
       "    ROC_AUC  \n",
       "0  0.700615  \n",
       "1  0.602437  \n",
       "2  0.680321  \n",
       "3  0.667538  \n",
       "4  0.601131  \n",
       "5  0.522283  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "cvec_knn = clf_model('cvec', 'knn', 5)\n",
    "tvec_knn = clf_model('tvec', 'knn', 5)\n",
    "pd.DataFrame(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Hyperparameter Tuning of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a robust machine learning model, we need to select the correct combination of hyperparameters.\n",
    "Recall that in the user defined function created earlier, if \"Gridsearch\" = True, the function will perform a gridsearch to find the optimal hyperparameters that will give the best score. GridsearchCV searches all combinations of paramters in for a model that will give the best peformance score. It is not practically feasible to run a GridSearchCV on all models due to the complexity and hence time taken. Hence, I will select only the best 3 models to perform hyperparameter tuning.\n",
    "\n",
    "From the above results table, seems like the Multinomial Naive Bayes Model, Logistic Regression and Random Forest perform the best.\n",
    "\n",
    "- Multinomial Naive Bayes: Based on Bayes's theorem - the assumption that each feature (in our case, each word) is independent of each other.\n",
    "- Logistic Regression:\n",
    "- Random Forest: Consists of n number of decision trees that act as an ensemble. Each decision tree makes a class prediction and the class with the most votes becomes the model's prediction.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = []\n",
    "\n",
    "# Vectorizer Parameters\n",
    "\n",
    "cvec_params = {\n",
    "    'cvec__max_features': [None],\n",
    "    'cvec__min_df':[3, 4, 5],\n",
    "    'cvec__max_df': [0.2, 0.3, 0.4],\n",
    "    'cvec__stop_words': [stopwords_list],\n",
    "    'cvec__ngram_range':[(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "tvec_params = {\n",
    "    'tvec__max_features': [None],\n",
    "    'tvec__min_df':[3, 4, 5],\n",
    "    'tvec__max_df': [0.2, 0.3, 0.4],\n",
    "    'tvec__stop_words': [stopwords_list],\n",
    "    'tvec__ngram_range':[(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "rf_pipe_cvec_params = {\n",
    "    'cvec__max_features': [100],\n",
    "    'cvec__max_df': [0.2, 0.3],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'rf__n_estimators': [50,75,100]}\n",
    "\n",
    "\n",
    "rf_pipe_tvec_params = {\n",
    "    'tvec__max_features': [100],\n",
    "    'tvec__max_df': [0.2, 0.3],\n",
    "    'tvec__min_df': [1, 2, 3],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'rf__n_estimators': [50,75,100]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "--- Best Parameters for log_reg,cvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': ['of',\n",
       "  'o',\n",
       "  'if',\n",
       "  'most',\n",
       "  'as',\n",
       "  'into',\n",
       "  'yourselves',\n",
       "  'any',\n",
       "  \"weren't\",\n",
       "  'ours',\n",
       "  'itself',\n",
       "  'that',\n",
       "  'our',\n",
       "  'doesn',\n",
       "  \"aren't\",\n",
       "  'd',\n",
       "  'having',\n",
       "  'out',\n",
       "  \"shan't\",\n",
       "  'both',\n",
       "  \"you're\",\n",
       "  'other',\n",
       "  'here',\n",
       "  \"shouldn't\",\n",
       "  'all',\n",
       "  'she',\n",
       "  'aren',\n",
       "  'off',\n",
       "  'herself',\n",
       "  'yourself',\n",
       "  'should',\n",
       "  'll',\n",
       "  'were',\n",
       "  \"needn't\",\n",
       "  'how',\n",
       "  'a',\n",
       "  'about',\n",
       "  'hasn',\n",
       "  \"haven't\",\n",
       "  'whom',\n",
       "  \"she's\",\n",
       "  'nor',\n",
       "  'wasn',\n",
       "  'ma',\n",
       "  'now',\n",
       "  'by',\n",
       "  'them',\n",
       "  \"don't\",\n",
       "  'y',\n",
       "  'what',\n",
       "  \"doesn't\",\n",
       "  'can',\n",
       "  'they',\n",
       "  'being',\n",
       "  'not',\n",
       "  'been',\n",
       "  'no',\n",
       "  'which',\n",
       "  'than',\n",
       "  \"won't\",\n",
       "  'mightn',\n",
       "  'its',\n",
       "  'during',\n",
       "  'between',\n",
       "  'why',\n",
       "  'because',\n",
       "  'shouldn',\n",
       "  'before',\n",
       "  'or',\n",
       "  'the',\n",
       "  \"mightn't\",\n",
       "  'against',\n",
       "  'don',\n",
       "  \"couldn't\",\n",
       "  'hadn',\n",
       "  'very',\n",
       "  'does',\n",
       "  'your',\n",
       "  'have',\n",
       "  'but',\n",
       "  'down',\n",
       "  'couldn',\n",
       "  'subreddit',\n",
       "  'on',\n",
       "  'at',\n",
       "  'his',\n",
       "  \"you'll\",\n",
       "  'to',\n",
       "  'then',\n",
       "  'where',\n",
       "  \"you'd\",\n",
       "  'this',\n",
       "  'her',\n",
       "  'own',\n",
       "  \"you've\",\n",
       "  'once',\n",
       "  \"that'll\",\n",
       "  'so',\n",
       "  'under',\n",
       "  'won',\n",
       "  'it',\n",
       "  'only',\n",
       "  's',\n",
       "  'through',\n",
       "  \"didn't\",\n",
       "  \"hasn't\",\n",
       "  'until',\n",
       "  \"wasn't\",\n",
       "  'mustn',\n",
       "  \"wouldn't\",\n",
       "  'over',\n",
       "  'up',\n",
       "  'do',\n",
       "  'few',\n",
       "  'hers',\n",
       "  'is',\n",
       "  'will',\n",
       "  'shan',\n",
       "  'me',\n",
       "  'themselves',\n",
       "  'reddit',\n",
       "  'each',\n",
       "  'ourselves',\n",
       "  'myself',\n",
       "  'my',\n",
       "  'after',\n",
       "  'from',\n",
       "  've',\n",
       "  'their',\n",
       "  'while',\n",
       "  'needn',\n",
       "  'weren',\n",
       "  'himself',\n",
       "  \"hadn't\",\n",
       "  'theirs',\n",
       "  \"mustn't\",\n",
       "  'in',\n",
       "  'are',\n",
       "  'ain',\n",
       "  'am',\n",
       "  'more',\n",
       "  'didn',\n",
       "  'was',\n",
       "  'with',\n",
       "  'you',\n",
       "  'there',\n",
       "  'isn',\n",
       "  'same',\n",
       "  'has',\n",
       "  'when',\n",
       "  't',\n",
       "  \"it's\",\n",
       "  'yours',\n",
       "  'did',\n",
       "  'he',\n",
       "  'doing',\n",
       "  'some',\n",
       "  'haven',\n",
       "  'and',\n",
       "  'too',\n",
       "  'these',\n",
       "  'those',\n",
       "  'for',\n",
       "  'm',\n",
       "  'him',\n",
       "  'above',\n",
       "  'such',\n",
       "  'wouldn',\n",
       "  'further',\n",
       "  'had',\n",
       "  'below',\n",
       "  'just',\n",
       "  'i',\n",
       "  \"isn't\",\n",
       "  're',\n",
       "  \"should've\",\n",
       "  'again',\n",
       "  'an',\n",
       "  'who',\n",
       "  'be',\n",
       "  'we']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for log_reg,cvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'log_reg',\n",
       " 'Vectorizer': 'cvec',\n",
       " 'Train Score': 0.9349724118977655,\n",
       " 'Test Score': 0.7404870624048706,\n",
       " 'Accuracy': 0.7404870624048706,\n",
       " 'Specificity': 0.5552984729291994,\n",
       " 'f_score': 0.8055502756130014,\n",
       " 'ROC_AUC': 0.7012233302812308}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "--- Best Parameters for log_reg,tvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_df': 0.2,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 3,\n",
       " 'tvec__ngram_range': (1, 2),\n",
       " 'tvec__stop_words': ['of',\n",
       "  'o',\n",
       "  'if',\n",
       "  'most',\n",
       "  'as',\n",
       "  'into',\n",
       "  'yourselves',\n",
       "  'any',\n",
       "  \"weren't\",\n",
       "  'ours',\n",
       "  'itself',\n",
       "  'that',\n",
       "  'our',\n",
       "  'doesn',\n",
       "  \"aren't\",\n",
       "  'd',\n",
       "  'having',\n",
       "  'out',\n",
       "  \"shan't\",\n",
       "  'both',\n",
       "  \"you're\",\n",
       "  'other',\n",
       "  'here',\n",
       "  \"shouldn't\",\n",
       "  'all',\n",
       "  'she',\n",
       "  'aren',\n",
       "  'off',\n",
       "  'herself',\n",
       "  'yourself',\n",
       "  'should',\n",
       "  'll',\n",
       "  'were',\n",
       "  \"needn't\",\n",
       "  'how',\n",
       "  'a',\n",
       "  'about',\n",
       "  'hasn',\n",
       "  \"haven't\",\n",
       "  'whom',\n",
       "  \"she's\",\n",
       "  'nor',\n",
       "  'wasn',\n",
       "  'ma',\n",
       "  'now',\n",
       "  'by',\n",
       "  'them',\n",
       "  \"don't\",\n",
       "  'y',\n",
       "  'what',\n",
       "  \"doesn't\",\n",
       "  'can',\n",
       "  'they',\n",
       "  'being',\n",
       "  'not',\n",
       "  'been',\n",
       "  'no',\n",
       "  'which',\n",
       "  'than',\n",
       "  \"won't\",\n",
       "  'mightn',\n",
       "  'its',\n",
       "  'during',\n",
       "  'between',\n",
       "  'why',\n",
       "  'because',\n",
       "  'shouldn',\n",
       "  'before',\n",
       "  'or',\n",
       "  'the',\n",
       "  \"mightn't\",\n",
       "  'against',\n",
       "  'don',\n",
       "  \"couldn't\",\n",
       "  'hadn',\n",
       "  'very',\n",
       "  'does',\n",
       "  'your',\n",
       "  'have',\n",
       "  'but',\n",
       "  'down',\n",
       "  'couldn',\n",
       "  'subreddit',\n",
       "  'on',\n",
       "  'at',\n",
       "  'his',\n",
       "  \"you'll\",\n",
       "  'to',\n",
       "  'then',\n",
       "  'where',\n",
       "  \"you'd\",\n",
       "  'this',\n",
       "  'her',\n",
       "  'own',\n",
       "  \"you've\",\n",
       "  'once',\n",
       "  \"that'll\",\n",
       "  'so',\n",
       "  'under',\n",
       "  'won',\n",
       "  'it',\n",
       "  'only',\n",
       "  's',\n",
       "  'through',\n",
       "  \"didn't\",\n",
       "  \"hasn't\",\n",
       "  'until',\n",
       "  \"wasn't\",\n",
       "  'mustn',\n",
       "  \"wouldn't\",\n",
       "  'over',\n",
       "  'up',\n",
       "  'do',\n",
       "  'few',\n",
       "  'hers',\n",
       "  'is',\n",
       "  'will',\n",
       "  'shan',\n",
       "  'me',\n",
       "  'themselves',\n",
       "  'reddit',\n",
       "  'each',\n",
       "  'ourselves',\n",
       "  'myself',\n",
       "  'my',\n",
       "  'after',\n",
       "  'from',\n",
       "  've',\n",
       "  'their',\n",
       "  'while',\n",
       "  'needn',\n",
       "  'weren',\n",
       "  'himself',\n",
       "  \"hadn't\",\n",
       "  'theirs',\n",
       "  \"mustn't\",\n",
       "  'in',\n",
       "  'are',\n",
       "  'ain',\n",
       "  'am',\n",
       "  'more',\n",
       "  'didn',\n",
       "  'was',\n",
       "  'with',\n",
       "  'you',\n",
       "  'there',\n",
       "  'isn',\n",
       "  'same',\n",
       "  'has',\n",
       "  'when',\n",
       "  't',\n",
       "  \"it's\",\n",
       "  'yours',\n",
       "  'did',\n",
       "  'he',\n",
       "  'doing',\n",
       "  'some',\n",
       "  'haven',\n",
       "  'and',\n",
       "  'too',\n",
       "  'these',\n",
       "  'those',\n",
       "  'for',\n",
       "  'm',\n",
       "  'him',\n",
       "  'above',\n",
       "  'such',\n",
       "  'wouldn',\n",
       "  'further',\n",
       "  'had',\n",
       "  'below',\n",
       "  'just',\n",
       "  'i',\n",
       "  \"isn't\",\n",
       "  're',\n",
       "  \"should've\",\n",
       "  'again',\n",
       "  'an',\n",
       "  'who',\n",
       "  'be',\n",
       "  'we']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METRICS for log_reg,tvec ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'log_reg',\n",
       " 'Vectorizer': 'tvec',\n",
       " 'Train Score': 0.8311523582013826,\n",
       " 'Test Score': 0.7434466429900219,\n",
       " 'Accuracy': 0.7434466429900219,\n",
       " 'Specificity': 0.49074502545118,\n",
       " 'f_score': 0.8147288715192965,\n",
       " 'ROC_AUC': 0.6898687813823065}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune for Logistic Regression\n",
    "cvec_lr_gs = clf_model('cvec', 'log_reg', 3, vec_params=cvec_params, grid_search=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\project_3\\3-web-scraping_v1.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tvec_lr_gs \u001b[39m=\u001b[39m clf_model(\u001b[39m'\u001b[39;49m\u001b[39mtvec\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlog_reg\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m3\u001b[39;49m, vec_params\u001b[39m=\u001b[39;49mtvec_params, grid_search\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\project_3\\3-web-scraping_v1.ipynb Cell 32\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X62sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X62sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         gs \u001b[39m=\u001b[39m GridSearchCV(pipe, param_grid \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mvec_params}, cv\u001b[39m=\u001b[39mcv_num, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X62sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         gs\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X62sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         pipe \u001b[39m=\u001b[39m gs\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X62sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>f_score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>cvec</td>\n",
       "      <td>0.934972</td>\n",
       "      <td>0.740487</td>\n",
       "      <td>0.740487</td>\n",
       "      <td>0.555298</td>\n",
       "      <td>0.805550</td>\n",
       "      <td>0.701223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>tvec</td>\n",
       "      <td>0.831152</td>\n",
       "      <td>0.743447</td>\n",
       "      <td>0.743447</td>\n",
       "      <td>0.490745</td>\n",
       "      <td>0.814729</td>\n",
       "      <td>0.689869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Vectorizer  Train Score  Test Score  Accuracy  Specificity  \\\n",
       "0  log_reg       cvec     0.934972    0.740487  0.740487     0.555298   \n",
       "1  log_reg       tvec     0.831152    0.743447  0.743447     0.490745   \n",
       "\n",
       "    f_score   ROC_AUC  \n",
       "0  0.805550  0.701223  \n",
       "1  0.814729  0.689869  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\project_3\\3-web-scraping_v1.ipynb Cell 34\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Tune for Random Forest using RandomizedSearchCV to improve model runtime\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cvec_rf_gs \u001b[39m=\u001b[39m clf_model(\u001b[39m'\u001b[39;49m\u001b[39mcvec\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrf\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m3\u001b[39;49m, vec_params\u001b[39m=\u001b[39;49mrf_pipe_cvec_params, grid_search\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\project_3\\3-web-scraping_v1.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m mod \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X44sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     rs \u001b[39m=\u001b[39m RandomizedSearchCV(pipe, param_distributions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mvec_params}, cv\u001b[39m=\u001b[39mcv_num, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X44sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     rs\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X44sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     pipe \u001b[39m=\u001b[39m rs\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#X44sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:933\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    931\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    932\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 933\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    934\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\.conda\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tune for Random Forest using RandomizedSearchCV to improve model runtime\n",
    "cvec_rf_gs = clf_model('cvec', 'rf', 3, vec_params=rf_pipe_cvec_params, grid_search=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tiffa\\Documents\\DSIF-SG-11\\project_3\\3-web-scraping_v1.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tiffa/Documents/DSIF-SG-11/project_3/3-web-scraping_v1.ipynb#Y106sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "tvec_rf_gs = clf_model('tvec', 'rf', 3, vec_params=rf_pipe_tvec_params, grid_search=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>CVEC</td>\n",
       "      <td>0.680676</td>\n",
       "      <td>0.681549</td>\n",
       "      <td>0.670726</td>\n",
       "      <td>0.217955</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TVEC</td>\n",
       "      <td>0.672114</td>\n",
       "      <td>0.670726</td>\n",
       "      <td>0.670726</td>\n",
       "      <td>0.217955</td>\n",
       "      <td>0.787568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Vectorizer  Train Score  Test Score  Accuracy  \\\n",
       "0  Logistic Regression       CVEC     0.680676    0.681549  0.670726   \n",
       "1  Logistic Regression       TVEC     0.672114    0.670726  0.670726   \n",
       "\n",
       "   Specificity  F1 Score  \n",
       "0     0.217955       NaN  \n",
       "1     0.217955  0.787568  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tvec_results = {\n",
    "    'Model': \"Logistic Regression\",\n",
    "    'Vectorizer': \"TVEC\",\n",
    "    'Train Score': tvec_lr_gs.score(X_train, y_train),\n",
    "    'Test Score': tvec_lr_gs.score(X_test, y_test),\n",
    "    'Accuracy': acc,\n",
    "    'Specificity': spec,\n",
    "    'F1 Score': f1_score\n",
    "}\n",
    "\n",
    "results_df.append(lr_tvec_results)\n",
    "pd.DataFrame(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Random Forest using *TFIFD Vectorizer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
