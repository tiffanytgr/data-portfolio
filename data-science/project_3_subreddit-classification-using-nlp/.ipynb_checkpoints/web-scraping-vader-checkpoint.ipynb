{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "725fd4ce-2e50-4600-a653-0c60a03de48e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tiffa\\AppData\\Roaming\\nltk_data...'nltk.download' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "!nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8082a3-cea5-401e-b968-6433dc354768",
   "metadata": {},
   "source": [
    "VADER’s SentimentIntensityAnalyzer() takes in a string and returns a dictionary of scores in these 4 categories: \n",
    "1) Negative\n",
    "2) Neutral\n",
    "3) Positive\n",
    "4) Compound (computed by normalizing the scores above)\n",
    "\n",
    "Explain why VADER is chosen\n",
    "https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00fe8635-53f6-41b2-9ad4-bc2fbaf3c96f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the data that was saved\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Import CountVectorizer and TFIDFVectorizer from feature_extraction.text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866e01d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nvidia = pd.read_csv('datasets/nvidia_reddit.csv',index_col=[0])\n",
    "amd = pd.read_csv('datasets/amd_reddit.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2677ce4e-8437-4aa8-b8ed-89eec204a6da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>Subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16d4gg0</td>\n",
       "      <td>2023-09-08 08:04:04</td>\n",
       "      <td>New to pc building</td>\n",
       "      <td>What’s better rtx 3090 for 700$-I’ve seen thes...</td>\n",
       "      <td>1</td>\n",
       "      <td>43VerLoner</td>\n",
       "      <td>3090 keeps its price from the VRAM it has. A 4...</td>\n",
       "      <td>Nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16d46z5</td>\n",
       "      <td>2023-09-08 07:47:35</td>\n",
       "      <td>Experiences</td>\n",
       "      <td>I personally play on a typical 1080ti system(...</td>\n",
       "      <td>7</td>\n",
       "      <td>SEALEJ2001</td>\n",
       "      <td>It's not you, just a combo of the game running...</td>\n",
       "      <td>Nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16d46z5</td>\n",
       "      <td>2023-09-08 07:47:35</td>\n",
       "      <td>Experiences</td>\n",
       "      <td>I personally play on a typical 1080ti system(...</td>\n",
       "      <td>7</td>\n",
       "      <td>SEALEJ2001</td>\n",
       "      <td>Starfield is CPU heavy, which one do you have?...</td>\n",
       "      <td>Nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16d46z5</td>\n",
       "      <td>2023-09-08 07:47:35</td>\n",
       "      <td>Experiences</td>\n",
       "      <td>I personally play on a typical 1080ti system(...</td>\n",
       "      <td>7</td>\n",
       "      <td>SEALEJ2001</td>\n",
       "      <td>The game is just awfully optimized. I just upg...</td>\n",
       "      <td>Nvidia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16d46z5</td>\n",
       "      <td>2023-09-08 07:47:35</td>\n",
       "      <td>Experiences</td>\n",
       "      <td>I personally play on a typical 1080ti system(...</td>\n",
       "      <td>7</td>\n",
       "      <td>SEALEJ2001</td>\n",
       "      <td>I tried using fsr but I didn't see any noticib...</td>\n",
       "      <td>Nvidia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                 date               title  \\\n",
       "0  16d4gg0  2023-09-08 08:04:04  New to pc building   \n",
       "1  16d46z5  2023-09-08 07:47:35         Experiences   \n",
       "2  16d46z5  2023-09-08 07:47:35         Experiences   \n",
       "3  16d46z5  2023-09-08 07:47:35         Experiences   \n",
       "4  16d46z5  2023-09-08 07:47:35         Experiences   \n",
       "\n",
       "                                            selftext  n_comments      author  \\\n",
       "0  What’s better rtx 3090 for 700$-I’ve seen thes...           1  43VerLoner   \n",
       "1   I personally play on a typical 1080ti system(...           7  SEALEJ2001   \n",
       "2   I personally play on a typical 1080ti system(...           7  SEALEJ2001   \n",
       "3   I personally play on a typical 1080ti system(...           7  SEALEJ2001   \n",
       "4   I personally play on a typical 1080ti system(...           7  SEALEJ2001   \n",
       "\n",
       "                                             comment Subreddit  \n",
       "0  3090 keeps its price from the VRAM it has. A 4...    Nvidia  \n",
       "1  It's not you, just a combo of the game running...    Nvidia  \n",
       "2  Starfield is CPU heavy, which one do you have?...    Nvidia  \n",
       "3  The game is just awfully optimized. I just upg...    Nvidia  \n",
       "4  I tried using fsr but I didn't see any noticib...    Nvidia  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvidia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59f00b6-ece9-4435-aae6-a93b012dcdb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Append both datasets as they have the same columns. Can distinguish source data using column \"Subreddit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9fca73-2c37-40e7-98b8-3fedcf851f16",
   "metadata": {},
   "source": [
    "#### Tokenise the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63cd2e4b-eb26-47fc-93e4-31850d8ef01f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                 date  \\\n",
      "0      16d4gg0  2023-09-08 08:04:04   \n",
      "1      16d46z5  2023-09-08 07:47:35   \n",
      "2      16d46z5  2023-09-08 07:47:35   \n",
      "3      16d46z5  2023-09-08 07:47:35   \n",
      "4      16d46z5  2023-09-08 07:47:35   \n",
      "...        ...                  ...   \n",
      "21604  15y5ju4  2023-08-22 13:15:45   \n",
      "21605  15y52uz  2023-08-22 12:57:05   \n",
      "21606  15y52uz  2023-08-22 12:57:05   \n",
      "21607  15y52uz  2023-08-22 12:57:05   \n",
      "21608  15y52uz  2023-08-22 12:57:05   \n",
      "\n",
      "                                                   title  \\\n",
      "0                                     New to pc building   \n",
      "1                                            Experiences   \n",
      "2                                            Experiences   \n",
      "3                                            Experiences   \n",
      "4                                            Experiences   \n",
      "...                                                  ...   \n",
      "21604  Is there a way to make a script using whatever...   \n",
      "21605  Half-Life 2 RTX, An RTX Remix Project - Announ...   \n",
      "21606  Half-Life 2 RTX, An RTX Remix Project - Announ...   \n",
      "21607  Half-Life 2 RTX, An RTX Remix Project - Announ...   \n",
      "21608  Half-Life 2 RTX, An RTX Remix Project - Announ...   \n",
      "\n",
      "                                                selftext  n_comments  \\\n",
      "0      What’s better rtx 3090 for 700$-I’ve seen thes...           1   \n",
      "1       I personally play on a typical 1080ti system(...           7   \n",
      "2       I personally play on a typical 1080ti system(...           7   \n",
      "3       I personally play on a typical 1080ti system(...           7   \n",
      "4       I personally play on a typical 1080ti system(...           7   \n",
      "...                                                  ...         ...   \n",
      "21604  I want to adjust the options within \"Adjust de...           5   \n",
      "21605                                                NaN           4   \n",
      "21606                                                NaN           4   \n",
      "21607                                                NaN           4   \n",
      "21608                                                NaN           4   \n",
      "\n",
      "               author                                            comment  \\\n",
      "0          43VerLoner  3090 keeps its price from the VRAM it has. A 4...   \n",
      "1          SEALEJ2001  It's not you, just a combo of the game running...   \n",
      "2          SEALEJ2001  Starfield is CPU heavy, which one do you have?...   \n",
      "3          SEALEJ2001  The game is just awfully optimized. I just upg...   \n",
      "4          SEALEJ2001  I tried using fsr but I didn't see any noticib...   \n",
      "...               ...                                                ...   \n",
      "21604  MetalNewspaper  You could use GeForce experience per game filt...   \n",
      "21605     Nestledrink  As a big gmod guy, this looks real good compar...   \n",
      "21606     Nestledrink  When you wanted to replay it, but wasn't sure ...   \n",
      "21607     Nestledrink                                 A thing of beauty.   \n",
      "21608     Nestledrink  I've never played half life, whenever this com...   \n",
      "\n",
      "      Subreddit                                          sentences  \\\n",
      "0        Nvidia  [3090 keeps its price from the VRAM it has., A...   \n",
      "1        Nvidia  [It's not you, just a combo of the game runnin...   \n",
      "2        Nvidia  [Starfield is CPU heavy, which one do you have...   \n",
      "3        Nvidia  [The game is just awfully optimized., I just u...   \n",
      "4        Nvidia  [I tried using fsr but I didn't see any notici...   \n",
      "...         ...                                                ...   \n",
      "21604    Nvidia  [You could use GeForce experience per game fil...   \n",
      "21605    Nvidia  [As a big gmod guy, this looks real good compa...   \n",
      "21606    Nvidia  [When you wanted to replay it, but wasn't sure...   \n",
      "21607    Nvidia                               [A thing of beauty.]   \n",
      "21608    Nvidia  [I've never played half life, whenever this co...   \n",
      "\n",
      "                                                   words  \n",
      "0      [3090, keeps, its, price, from, the, VRAM, it,...  \n",
      "1      [It, 's, not, you, ,, just, a, combo, of, the,...  \n",
      "2      [Starfield, is, CPU, heavy, ,, which, one, do,...  \n",
      "3      [The, game, is, just, awfully, optimized, ., I...  \n",
      "4      [I, tried, using, fsr, but, I, did, n't, see, ...  \n",
      "...                                                  ...  \n",
      "21604  [You, could, use, GeForce, experience, per, ga...  \n",
      "21605  [As, a, big, gmod, guy, ,, this, looks, real, ...  \n",
      "21606  [When, you, wanted, to, replay, it, ,, but, wa...  \n",
      "21607                          [A, thing, of, beauty, .]  \n",
      "21608  [I, 've, never, played, half, life, ,, wheneve...  \n",
      "\n",
      "[21609 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences and words\n",
    "\n",
    "# Ensure 'comment' column is converted to strings\n",
    "nvidia['comment'] = nvidia['comment'].apply(lambda x: str(x) if x is not None else \"\")\n",
    "\n",
    "# Tokenize sentences and words\n",
    "nvidia['sentences'] = nvidia['comment'].apply(sent_tokenize)\n",
    "nvidia['words'] = nvidia['sentences'].apply(lambda x: sum([word_tokenize(sentence) for sentence in x], []))\n",
    "\n",
    "# Print the DataFrame\n",
    "print(nvidia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50e0167-d3b3-443b-90d1-630c7ff0e11b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [3090, keeps, its, price, from, the, VRAM, it,...\n",
       "1        [It, 's, not, you, ,, just, a, combo, of, the,...\n",
       "2        [Starfield, is, CPU, heavy, ,, which, one, do,...\n",
       "3        [The, game, is, just, awfully, optimized, ., I...\n",
       "4        [I, tried, using, fsr, but, I, did, n't, see, ...\n",
       "                               ...                        \n",
       "21604    [You, could, use, GeForce, experience, per, ga...\n",
       "21605    [As, a, big, gmod, guy, ,, this, looks, real, ...\n",
       "21606    [When, you, wanted, to, replay, it, ,, but, wa...\n",
       "21607                            [A, thing, of, beauty, .]\n",
       "21608    [I, 've, never, played, half, life, ,, wheneve...\n",
       "Name: words, Length: 21609, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvidia['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7940d587-f3a6-402b-bfd6-149632ecbc2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function Pre-process the bag of words using regex\n",
    "\n",
    "def preprocessing(word_list):\n",
    "    # Combine words into a single text\n",
    "    text = ' '.join(word_list)\n",
    "    # Remove new lines\n",
    "    text = text.replace('\\n', ' ').lower()\n",
    "    # Remove emoticons using regular expressions\n",
    "    text = re.sub(':d', '', text).strip()\n",
    "    text = re.sub(':p', '', text).strip()\n",
    "    # Remove HTML markers and punctuation using regular expressions\n",
    "    text = re.sub('xa0', '', text).strip()\n",
    "    text = re.sub('x200b', '', text).strip()\n",
    "    text = re.sub('[^a-zA-Z\\s]', '', text).strip()\n",
    "    # Split the preprocessed text back into a list of words\n",
    "    preprocessed_words = text.split()\n",
    "    \n",
    "    return preprocessed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d176cbc-235e-4cde-9065-0aefd34ff5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the preprocessing function and create a new column\n",
    "nvidia['preprocessed_words'] = nvidia['words'].apply(preprocessing)\n",
    "words_list = nvidia['preprocessed_words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3213326a-205c-45af-a9fa-41c1cd4075eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Lemmatize tokens.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tokens_lem \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m words_list]\n",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Lemmatize tokens.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tokens_lem \u001b[38;5;241m=\u001b[39m [\u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m words_list]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:2096\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy\u001b[1;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# 0. Check the exception lists\u001b[39;00m\n\u001b[0;32m   2095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_exceptions:\n\u001b[1;32m-> 2096\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexceptions\u001b[49m:\n\u001b[0;32m   2097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m filter_forms([form] \u001b[38;5;241m+\u001b[39m exceptions[form])\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;66;03m# 1. Apply rules once to the input to get y1, y2, y3, etc.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Lemmatizing\n",
    "# Instantiate lemmatizer.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Lemmatize tokens.\n",
    "tokens_lem = [lemmatizer.lemmatize(i) for i in words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129ae4b-9611-43e7-94e5-4006ae191cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nvidia_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30dbee9-6d89-450d-9039-266bb3abb25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent_tokenize(nvidia_comments.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04abf793-a184-4cce-9571-3c1898f549e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b2383-6913-4e02-8475-3120376caf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nvidia['scores'] = nvidia['comment'].apply(lambda review:sid.polarity_scores(comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60f015-c335-467d-82bb-b2984eaaabaf",
   "metadata": {},
   "source": [
    "##### Basic NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b280c-a0e7-4e2a-8e79-d93e2a788f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = nvidia['comment'][50]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ed4cf-51a6-4cd3-8200-12ead5e5a6c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(example)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be3f0a-8b21-4778-a0e9-f229a867c522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# part of speech (POS)\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243035c8-1668-41d7-95ee-acbb9714dde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_links(nvidia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f645e-3068-4432-be2b-f6f50fc8f8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nvidia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d57a9-7f7c-4017-99bd-87bc8480d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262e115-fe38-4f9b-9160-dd75762d065e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nvidia_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654418e-d5e9-4f37-bee7-f33f2963a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at sklearn's stopwords.\n",
    "print(CountVectorizer(stop_words = 'english').get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae086edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nvidia.isnull().sum()[nvidia.isnull().sum() > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2368e7c-7c88-44e5-b278-fa11b5f22afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
