{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00948e3-ee8f-43f8-909e-604a8cfa3528",
   "metadata": {},
   "source": [
    "## Project 3 - Subreddit Classification using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a3256",
   "metadata": {},
   "source": [
    "### I: Webscraping from Reddit using PRAW API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d17dd",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "**Reddit** is a network of communities where people can post comments and discuss just about any topic under the sun. Each community is known as a Subreddit.\n",
    " **AMD** and **Nvidia** are two major competitors in the graphic cards manufacturing space, with AMD widely regarded as the more \"budget\" option and hence market perception is that they are of lower quality. This project will be leveraging the AMD and Nvidia subreddit communities as the database.\n",
    "\n",
    "- Stakeholders: AMD Strategy Team (Consumer Products)\n",
    "- Who we are: Consultants to help boost AMD sales<br>\n",
    "\n",
    "#### Problem Statement\n",
    "As consultants, AMD has hired our team to analyse how to improve sales of AMD products. It is unclear if the perception of AMD products is driven by a *marketing* or *engineering* issue. To understand market sentiments of AMD products, we have decided to leverage Reddit as one of the data sources as it is an uncensored forum.\n",
    "\n",
    "#### Objective\n",
    "1. Classify whether or not a comment is from the AMD or Nvidia Subreddit community -->  a binary classification task - to determine which subreddit a post came from based on its content. This is to future deployment of this model is scalable and possible\n",
    "2. On top of the classification task in point 1, sentiment analysis will also be explored to understand the differences between the two subreddits. So that we can do a mini root cause analysis on the reason for AMD's comparatively lower sales than Nvidia. Hence we can advise the AMD team which department to deploy more resources into (i.e engineering or marketing team)\n",
    "\n",
    "#### Success Metrics\n",
    "1. F1 Score\n",
    "2. ROC-AUC Score\n",
    "\n",
    "This is because we are not overly concerned about minimizing either false negatives or false positives -- ideal scenario is to minimize both.\n",
    "\n",
    "#### Workflow:\n",
    "- Notebook 1: Webscraping from Reddit using PRAW API\n",
    "- Notebook 2: EDA, Preprocessing and Sentiment Analysis\n",
    "- Notebook 3: Modelling and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d38b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfbb2be",
   "metadata": {},
   "source": [
    "#### Webscraping Using PRAW API\n",
    "I have opted to use PRAW API as 1) it is the official API wrapper for Reddit, hence it provides reliable access to Reddit's data and functionality and 2) well-documented, making it easy to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35579762-edee-4ac0-8a17-4acdfdffea95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install praw\n",
    "# https://www.youtube.com/watch?v=NRgfgtzIhBQ&t=530\n",
    "# https://praw.readthedocs.io/en/latest/code_overview/models/submission.html\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3dea30-2e95-47c7-a13e-ae48d8b75f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client id: assgnxQ_xl3vDcnijLsTuw\n",
    "# secret: YE9jFCFSwjWCQ81hh-1cczz1oc-zoQ\n",
    "\n",
    "reddit = praw.Reddit(client_id = 'assgnxQ_xl3vDcnijLsTuw' ,\n",
    "                    client_secret = 'YE9jFCFSwjWCQ81hh-1cczz1oc-zoQ',\n",
    "                    username = 'intelligentstraw',\n",
    "                    password = 'intelligentpassword',\n",
    "                    user_agent = 'tiffanyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124260f-3fde-4f77-a5fc-933e07d76907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intelligentstraw\n"
     ]
    }
   ],
   "source": [
    "# check if can access API\n",
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a588634-3792-4675-9f5d-0831a984f1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subreddit_nvidia = reddit.subreddit('nvidia')\n",
    "new_nvidia = subreddit_nvidia.new(limit=500) # get what is the latest news in reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c749325-ddda-4d9c-a167-4a639f1d95a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter to posts from 2022 onwards\n",
    "\n",
    "start_date = '01-01-22 00:00:00'\n",
    "start_date = datetime.datetime.strptime(start_date, '%d-%m-%y %H:%M:%S').timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037b6d5-4a9f-42db-8ced-6a7896c26ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "Error processing post: received 429 HTTP response\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "data = []  # Initialize lists to store data\n",
    "counter = 0\n",
    "\n",
    "for post in new_nvidia:\n",
    "    date = post.created_utc\n",
    "    try:\n",
    "        if not post.stickied and date > start_date:   # filter to posts from 2022 onwards only\n",
    "            post_data = {\n",
    "                'id':post.id,\n",
    "                 'date': post.created_utc,\n",
    "                'title': post.title,\n",
    "                'selftext': post.selftext,\n",
    "                'n_comments': post.num_comments,\n",
    "                 'author': post.author\n",
    "            }\n",
    "\n",
    "            post.comments.replace_more(limit=None)  # Fetch all comments from each post\n",
    "            for comment in post.comments.list():\n",
    "                try:\n",
    "                    comment_text = comment.body.encode(\"utf-8\", errors='ignore').decode(\"utf-8\", errors='ignore')\n",
    "                    comment_data = post_data.copy()  # Copy post data for each comment \n",
    "                    comment_data['comment'] = comment_text\n",
    "                    data.append(comment_data) # put comments in rows\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing comment: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing post: {e}\")\n",
    "        \n",
    "    counter += 1 # counter of no. of posts being scraped\n",
    "    print(counter)\n",
    "\n",
    "# Create a DataFrame \n",
    "df_nvidia = pd.DataFrame(data)\n",
    "\n",
    "# Create column to identify that it is Nvidia posts\n",
    "df_nvidia['Subreddit'] = \"Nvidia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae40c55-25f9-4688-9247-660b4494a65e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert date to datetime format\n",
    "df_nvidia['date'] = pd.to_datetime(df_nvidia['date'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287fd9f-dffe-445a-86ba-86ea5e690160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21823, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of data\n",
    "df_nvidia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab8b2c-4a5d-43fb-b33d-27106a5e7b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21609, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nvidia = df_nvidia.drop_duplicates() # drop duplicates\n",
    "df_nvidia.reset_index(drop=True, inplace=True)\n",
    "df_nvidia.shape # check no. of rows after dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4751bd-f411-4e14-b551-76f63535a625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export as csv\n",
    "df_nvidia.to_csv('datasets/nvidia_reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9eccc4-bca4-4744-9fe1-b836e5dfb332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view posts with top comments\n",
    "selected_nvda = df_nvidia[['title', 'n_comments']].drop_duplicates()\n",
    "sorted_nvda = selected_nvda.sort_values(by='n_comments', ascending=False)\n",
    "sorted_nvda.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d7502-5d60-4c67-9a83-f6748a76c98e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Repeat the same process for AMD\n",
    "\n",
    "subreddit_amd = reddit.subreddit('AMD')\n",
    "new_amd = subreddit_amd.new(limit=500) # get what is the latest news in reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0389bd-343e-4bb4-ae40-41573c526aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "Error processing post: received 429 HTTP response\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "data = []  # Initialize lists to store data\n",
    "counter = 0\n",
    "\n",
    "for post in new_amd:\n",
    "    date = post.created_utc\n",
    "    try:\n",
    "        if not post.stickied and date > start_date:   # filter to posts from 2022 onwards only\n",
    "            post_data = {\n",
    "                'id':post.id,\n",
    "                 'date': post.created_utc,\n",
    "                'title': post.title,\n",
    "                'selftext': post.selftext,\n",
    "                'n_comments': post.num_comments,\n",
    "                 'author': post.author\n",
    "            }\n",
    "\n",
    "            post.comments.replace_more(limit=None)  # Fetch all comments from each post\n",
    "            for comment in post.comments.list():\n",
    "                try:\n",
    "                    comment_text = comment.body.encode(\"utf-8\", errors='ignore').decode(\"utf-8\", errors='ignore')\n",
    "                    comment_data = post_data.copy()  # Copy post data for each comment \n",
    "                    comment_data['comment'] = comment_text\n",
    "                    data.append(comment_data) # put comments in rows\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing comment: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing post: {e}\")\n",
    "        \n",
    "    counter += 1 # counter of no. of posts being scraped\n",
    "    print(counter)\n",
    "\n",
    "# Create a DataFrame \n",
    "df_amd = pd.DataFrame(data)\n",
    "\n",
    "# Create column to identify that it is Nvidia posts\n",
    "df_amd['Subreddit'] = \"AMD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb885f-e93e-4292-a3ba-9ba3de849705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert date to datetime format\n",
    "df_amd['date'] = pd.to_datetime(df_amd['date'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801c3b7-c49b-4e0f-9922-9cbdc2cb1a30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38032, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "df_amd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571fbcb0-fc6c-4deb-985e-69320bd19038",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37520, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amd = df_amd.drop_duplicates() # drop duplicates\n",
    "df_amd.reset_index(drop=True, inplace=True)\n",
    "df_amd.shape # check no. of rows after dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df542c-a990-47d5-947f-4b20c5fff66d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_amd.to_csv('datasets/amd_reddit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a280679",
   "metadata": {},
   "source": [
    "With that, I have successfully completed the main objective of the notebook, which is to scrape the Nvidia and AMD posts from the Reddit website. This data was then exported to csv, and will be used for EDA and modelling in Notebooks 2 and 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
